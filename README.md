The project is derived from the "Generative AI with Large Language Models" course offered by Coursera.org, in partnership with AWS and DeepLearning.ai. It provides a hands-on experience in training and fine-tuning large language models (LLMs) using advanced tools and techniques, as well as evaluating and deploying them in real-world applications. It includes both instructure codes and my own codes 

Lab 1: This notebook covers prompt engineering, zero shot, one shot and few shot inferences in dialog summarization 
Lab 2: This notebook focuses on fine-tuning and evaluating FLANT5 using prompt datasets and parameter-efficient fine-tuning (PEFT)
Lab 3: This notebook covers fine-tuning a FLAN-T5 model to generate less toxic content with Meta AI's hate speech reward model using reinforcement learning (PPO)
